{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6604c6a-8652-4752-a893-fc2989aed9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import math\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import IPython.display as ipd\n",
    "! pip install librosa\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97917ddd-47b4-4e52-82f3-20232a09e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd all.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0cbc8-611f-4f46-a55a-45097b089f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd tone_perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a9b8d7-f100-495c-adfe-cc1b793f2075",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd mfcc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d472dd2-b1ec-442f-918b-e459bdb2e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "file_path = \"tone_perfect_all_mp3.zip\"\n",
    "\n",
    "# create a ZipFile object\n",
    "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "    # extract all the contents\n",
    "    zip_ref.extractall(\"all.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f85a9ae-b53c-41ff-8cf6-5683a0fca96a",
   "metadata": {},
   "source": [
    "Visualizations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b66a5-7ee4-4c97-b030-3c3cc5684746",
   "metadata": {},
   "source": [
    "First Tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8020fe7-cdcc-4e08-84e0-67b275beacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d4b15-7b20-48f8-a499-816a9cdd4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Waveform\n",
    "first_file = 'all.mp3/tone_perfect/ma1_MV1_MP3.mp3'\n",
    "first, sr = librosa.core.load(first_file)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "#plotting the sampled signal\n",
    "librosa.display.waveshow(first, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e271ac-12a8-4349-932f-00f52cc0928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFCC 1\n",
    "first, sr = librosa.core.load(first_file)\n",
    "D = librosa.stft(first)\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "plt.figure()\n",
    "librosa.display.specshow(S_db)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b9f00-558f-4aa9-925e-b2f93f51fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFCC 2\n",
    "mfcc = librosa.feature.mfcc(y=first, sr=sr, n_mfcc=60)\n",
    "plt.imshow(mfcc, aspect='auto', cmap=cm.viridis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6c6d9d-954a-4b79-91f8-df7b5f66f5e2",
   "metadata": {},
   "source": [
    "Second Tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27207ac8-8476-4c1c-946b-9733157fa6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Waveform\n",
    "second_file = 'drive/My Drive/all.mp3/tone_perfect/ma2_MV1_MP3.mp3'\n",
    "second, sr = librosa.core.load(second_file)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "#plotting the sampled signal\n",
    "librosa.display.waveshow(second, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eda99a-5efd-44b2-aafd-4fd355dd9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFCC 1\n",
    "second, sr = librosa.core.load(second_file)\n",
    "D = librosa.stft(second)\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "plt.figure()\n",
    "librosa.display.specshow(S_db)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc9702-d29a-4d59-9dca-9fa133bd758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFCC 2\n",
    "mfcc = librosa.feature.mfcc(y=second, sr=sr, n_mfcc=60)\n",
    "plt.imshow(mfcc, aspect='auto', cmap=cm.viridis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe4863-ee4a-49de-bc56-d9e1acd79457",
   "metadata": {},
   "source": [
    "Third Tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337c98d-0c3f-4b22-9b69-4d82709a9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Waveform \n",
    "third_file = 'drive/My Drive/all.mp3/tone_perfect/ma3_MV1_MP3.mp3'\n",
    "third, sr = librosa.core.load(third_file)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "#plotting the sampled signal\n",
    "librosa.display.waveshow(third, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70475a3d-db05-4519-b8ae-5b77012b86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFCC 1\n",
    "third, sr = librosa.core.load(third_file)\n",
    "D = librosa.stft(third)\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "plt.figure()\n",
    "librosa.display.specshow(S_db)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a38e392-7cf9-4058-b0fc-7cb50d933cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFCC 2\n",
    "mfcc = librosa.feature.mfcc(y=third, sr=sr, n_mfcc=60)\n",
    "plt.imshow(mfcc, aspect='auto', cmap=cm.viridis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6acaed1-038c-4132-92f7-37b2182712cc",
   "metadata": {},
   "source": [
    "Fourth Tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f315fc9-a4cf-4cd3-b27d-a4f819b0128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Waveform\n",
    "fourth_file = 'drive/My Drive/all.mp3/tone_perfect/ma4_MV1_MP3.mp3'\n",
    "fourth, sr = librosa.core.load(fourth_file)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "#plotting the sampled signal\n",
    "librosa.display.waveshow(fourth, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45cb2a-2334-4e7d-aebd-c32204b46bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFCC 1\n",
    "fourth, sr = librosa.core.load(fourth_file)\n",
    "D = librosa.stft(fourth)\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "plt.figure()\n",
    "librosa.display.specshow(S_db)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ec751-e25f-4863-945f-4a8df830d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFCC 2\n",
    "mfcc = librosa.feature.mfcc(y=fourth, sr=sr, n_mfcc=60)\n",
    "plt.imshow(mfcc, aspect='auto', cmap=cm.viridis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3789d994-f994-402b-b4c1-5432736125a5",
   "metadata": {},
   "source": [
    "Organizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f6f25-dab5-4c8c-9e21-861441f2e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43888166-d818-424b-8d6c-0ee7de760240",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path(\"all.mp3/tone_perfect\").iterdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0875a-651c-4516-97b7-cebedd97f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_folder = \"/Users/lolamanning/NLP_Tones/all.mp3/tone_perfect\"\n",
    "mp3_files = os.listdir(mp3_folder)\n",
    "\n",
    "# Create folders based on the third character\n",
    "for mp3_file in mp3_files:\n",
    "    third_char = mp3_file[-13]\n",
    "\n",
    "    char_folder = os.path.join(mp3_folder, third_char)\n",
    "    if not os.path.exists(char_folder):\n",
    "        os.makedirs(char_folder)\n",
    "\n",
    "    # Move the file to the respective character folder\n",
    "    source_path = os.path.join(mp3_folder, mp3_file)\n",
    "    destination_path = os.path.join(char_folder, mp3_file)\n",
    "    shutil.move(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed0e380-6b35-4583-ae3e-b4f8042e0d10",
   "metadata": {},
   "source": [
    "MP3 to MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20b657-aa00-423e-9ec3-ed70b44e3569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp3tomfcc(file_path, max_pad):\n",
    "  audio, sample_rate = librosa.core.load(file_path)\n",
    "  mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=60)\n",
    "  pad_width = max_pad - mfcc.shape[1]\n",
    "  mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "  return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464ba1be-5a2c-4c00-a0f4-1bf9f81bf29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '/Users/lolamanning/NLP_Tones/all.mp3/tone_perfect'\n",
    "mfcc_folders = ['mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4']\n",
    "for folder_name in mfcc_folders:\n",
    "    folder_path = os.path.join(base_folder, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae59f3-432b-4d6e-a0fd-4630df39e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, output_folder, num_mfcc=13, n_fft=2048, hop_length=512):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".mp3\"):\n",
    "            mp3_path = os.path.join(folder_path, filename)\n",
    "            # Apply mp3_to_mfcc function\n",
    "            mfccs = mp3tomfcc(mp3_path, max_pad=100)\n",
    "            # Save or further process the MFCCs as needed\n",
    "            # For example, you can save the MFCCs to a file\n",
    "            output_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}.npy\")\n",
    "            np.save(output_path, mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c028ca-784b-4b3d-8f54-574020e5ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_base_folder = '/Users/lolamanning/NLP_Tones/all.mp3/tone_perfect'\n",
    "output_base_folder = '/Users/lolamanning/NLP_Tones/all.mp3/tone_perfect'\n",
    "\n",
    "input_folders = ['1', '2', '3', '4']\n",
    "output_folders = ['mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4']\n",
    "\n",
    "# Process and move data\n",
    "for input_folder, output_folder in zip(input_folders, output_folders):\n",
    "    current_input_folder = os.path.join(input_base_folder, input_folder)\n",
    "    current_output_folder = os.path.join(output_base_folder, output_folder)\n",
    "\n",
    "    # Process the current folder\n",
    "    process_folder(current_input_folder, current_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05929dc7-77f6-4f73-9cda-0b842e86935d",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b849661-9733-4340-9679-4d3a6b01aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e5c05-1bc6-422a-8ed2-7a2ca667c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3668d-798d-441c-b2e3-62c512b6c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9779385-9914-4a82-864b-f65a176c1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_for_folder(folder_path):\n",
    "    # Get a list of MFCC file paths\n",
    "    mfcc_file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.npy')]\n",
    "\n",
    "    # Load each MFCC file and preprocess the data\n",
    "    preprocessed_data = []\n",
    "    for mfcc_path in mfcc_file_paths:\n",
    "        mfccs = np.load(mfcc_path)\n",
    "        preprocessed_data.append(preprocess_data(mfccs))\n",
    "\n",
    "    return np.array(preprocessed_data)\n",
    "\n",
    "def preprocess_data(X):\n",
    "    # If X is 3D (num_samples, num_mfcc, frame_length)\n",
    "    if len(X.shape) == 3:\n",
    "        # Flatten the MFCC matrices along the frame_length dimension\n",
    "        X_flat = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
    "    # If X is already 2D (num_samples, num_mfcc * frame_length)\n",
    "    elif len(X.shape) == 2:\n",
    "        X_flat = X\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_flat)\n",
    "\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d825a-ca48-4827-8e44-32e6e39ca9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_for_folder(folder_path, max_frames=None):\n",
    "    # Get a list of MFCC file paths in the specified folder\n",
    "    mfcc_file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.npy')]\n",
    "\n",
    "    # Load each MFCC file and preprocess the data\n",
    "    preprocessed_data = []\n",
    "    for mfcc_path in mfcc_file_paths:\n",
    "        mfccs = np.load(mfcc_path)\n",
    "\n",
    "        # Pad or truncate MFCCs to a fixed number of frames\n",
    "        if max_frames is not None:\n",
    "            mfccs = pad_or_truncate_mfcc(mfccs, max_frames)\n",
    "\n",
    "        preprocessed_data.append(preprocess_data(mfccs))\n",
    "\n",
    "    return np.array(preprocessed_data)\n",
    "\n",
    "def pad_or_truncate_mfcc(mfccs, max_frames):\n",
    "    current_frames = mfccs.shape[1]\n",
    "\n",
    "    # Pad or truncate the MFCCs to the specified number of frames\n",
    "    if current_frames < max_frames:\n",
    "        padding = max_frames - current_frames\n",
    "        mfccs = np.pad(mfccs, ((0, 0), (0, padding)), mode='constant')\n",
    "    elif current_frames > max_frames:\n",
    "        mfccs = mfccs[:, :max_frames]\n",
    "\n",
    "    return mfccs\n",
    "\n",
    "# Specify the base path to the mfcc folders\n",
    "mfcc_base_path = '/Users/lolamanning/NLP_Tones/all.mp3/tone_perfect'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890fafac-6d4f-42e2-920d-fe80e27cea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder_name in ['mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4']:\n",
    "    mfcc_folder_path = os.path.join(mfcc_base_path, folder_name)\n",
    "\n",
    "    # Preprocess data for the current mfcc folder\n",
    "    preprocessed_data = preprocess_data_for_folder(mfcc_folder_path, max_frames=100)  # Adjust max_frames as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc0525-6e04-40a1-bf20-3f9296931436",
   "metadata": {},
   "source": [
    "Building Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d07d21d-aaa3-46f2-87f4-61a7d926f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(base_path, folders, max_frames=None):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for label, folder_name in enumerate(folders, start=1):\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "\n",
    "        # Preprocess data for the current folder\n",
    "        preprocessed_data = preprocess_data_for_folder(folder_path, max_frames=max_frames)\n",
    "\n",
    "        if preprocessed_data.size > 0:  # Check if the array is non-empty\n",
    "            data.append(preprocessed_data)\n",
    "            labels.extend([label] * preprocessed_data.shape[0])\n",
    "\n",
    "    if data:\n",
    "        # Flatten the data before returning\n",
    "        return np.concatenate(data, axis=0).reshape(len(labels), -1), np.array(labels)\n",
    "    else:\n",
    "        return np.empty((0,)), np.empty((0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6bf220-409c-4975-8f91-3eb8a9fd2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_base_path = '/Users/lolamanning/NLP_Tones/all.mp3/tone_perfect'\n",
    "folders = ['mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9d02fd-2eb9-4c7d-810a-5eda2733c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset\n",
    "X, y = build_dataset(mfcc_base_path, folders, max_frames=100)  # Adjust max_frames as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24582274-f89a-4317-8a98-dee60f97c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b5b3fe-9067-499e-8828-cc620c5b35a4",
   "metadata": {},
   "source": [
    "SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4430c47e-bdff-460d-b2d8-dcfd5c351bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a SVM model\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59fbb09-1381-40d3-bf04-2ee7e8fbd3c6",
   "metadata": {},
   "source": [
    "CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0dc83-544d-4d4e-ad8d-899a5329a29f",
   "metadata": {},
   "source": [
    "I think this is repetitive \n",
    "def build_cnn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be00f4-5a69-48cf-b077-8fb9b41e3ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = build_dataset(mfcc_base_path, folders, max_frames=100)  # Adjust max_frames as needed\n",
    "\n",
    "# One-hot encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_one_hot = to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3fd641-7967-49a3-ac0f-98e6d08b8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42, stratify=y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f1847-e7f9-4790-b425-325c6711237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5a3ad0-6261-4d04-80e7-2cc2b46a4047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create CNN model\n",
    "input_shape = (X_train.shape[1], 1)\n",
    "cnn_model = models.Sequential()\n",
    "cnn_model.add(layers.Conv1D(32, 3, activation='relu', input_shape=input_shape))\n",
    "cnn_model.add(layers.MaxPooling1D(2))\n",
    "cnn_model.add(layers.Conv1D(64, 3, activation='relu'))\n",
    "cnn_model.add(layers.MaxPooling1D(2))\n",
    "cnn_model.add(layers.Conv1D(128, 3, activation='relu'))\n",
    "cnn_model.add(layers.MaxPooling1D(2))\n",
    "cnn_model.add(layers.Flatten())\n",
    "cnn_model.add(layers.Dense(128, activation='relu'))\n",
    "cnn_model.add(layers.Dropout(0.5))\n",
    "cnn_model.add(layers.Dense(4, activation='softmax'))  # Assuming 4 classes for tones\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "accuracy = cnn_model.evaluate(X_test_reshaped, y_test)[1]\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d48de8-153f-47e0-860d-a4ca3d4eede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save('cnn_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde6930-2b9c-46df-a8a3-03dc709ac7df",
   "metadata": {},
   "source": [
    "Load in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5d088b-cb04-4515-8573-bbd620c7cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83cf0cd-ae54-45f5-9eb3-6343ea9e9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('cnn_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a9401b-2e1e-4eba-bccc-4805038908dc",
   "metadata": {},
   "source": [
    "Create Input Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0107a350-3c73-4d55-ad5b-e97fbc92487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd53717-9f5a-4804-a197-b20bb1722c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import os\n",
    "import time  # Added import for the time module\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6dd10f-92c9-45ba-bfb2-638722d5b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#credit for this code to tayburke (cited in write-up)\n",
    "frame_rate = 44100\n",
    "duration = 1.4 #aligns with the max time for the data recordings [sec]\n",
    "\n",
    "print(\"Recording in...\")\n",
    "pause = 3\n",
    "\n",
    "while pause > 0:\n",
    "    print(\"{}\".format(pause))\n",
    "    pause -= 1\n",
    "    time.sleep(1)\n",
    "print(\"RECORDING\")\n",
    "\n",
    "recording = sd.rec(int(duration * frame_rate), samplerate = frame_rate, channels = 1)\n",
    "recording_num = len(os.listdir('input_audio/')) + 1\n",
    "recording_name = 'input_audio/sample_audio_{}.mp3'.format(recording_num)\n",
    "sd.wait()\n",
    "write(recording_name, frame_rate, recording)\n",
    "\n",
    "print(\"\\nFinished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74f572-3f12-42db-86ae-afb92d263a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3fe9d-2263-4618-b438-46335aa24552",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_file_base = '/Users/lolamanning/NLP_Tones/input_audio/'\n",
    "\n",
    "def import_file(filename):\n",
    "    #load in file and convert to mfccs\n",
    "    file = os.path.join(mp3_file_base, filename)\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    #plot mfccs\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(librosa.power_to_db(mfccs, ref=np.max), y_axis='mel', x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('MFCCs')\n",
    "    plt.show()\n",
    "    #pad mfccs\n",
    "    desired_length = 6000\n",
    "    mfccs_padded = np.pad(mfccs, ((0, 0), (0, max(0, desired_length - mfccs.shape[1]))), mode='constant', constant_values=0)\n",
    "    #Make predictions\n",
    "    predictions = loaded_model.predict(mfccs_padded)\n",
    "    predicted_tone_index = np.argmax(predictions)\n",
    "    # Map the index to the actual tone (assuming tones are 1, 2, 3, 4)\n",
    "    predicted_tone = predicted_tone_index + 1  # Adding 1 to match the tone values\n",
    "    return predicted_tone\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
